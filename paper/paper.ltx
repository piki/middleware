\documentclass{llncs}
\usepackage{makeidx}  % allows for indexgeneration
\usepackage{subfigure}
\usepackage{tikz}
\usepackage{url}
\usepackage{cite}
\frontmatter
\pagestyle{headings}
\mainmatter
\title{Peer-to-Peer Keyword Search: A Retrospective}
\titlerunning{Peer-to-Peer Search}
\author{Patrick Reynolds\inst{1} \and Amin Vahdat\inst{2}}
\authorrunning{Reynolds and Vahdat}
\institute{GitHub, Inc.
\and
University of California, San Diego and Google, Inc.}

\date{}
\begin{document}
\maketitle

\begin{abstract}
Peer-to-peer systems have been an exciting area of research.  Challenges in building them have included scalability, reliability, security, and---of particular interest to these authors---search functionality.  This paper surveys some of the history of the field, looks at the lasting impacts of peer-to-peer research, and provides at least one view of where we go from here.
\end{abstract}

\section{Introduction}
2001 was an exciting time for research on peer-to-peer systems.  Napster~\cite{napster} had recently been shut down for abetting widespread copyright violation~\cite{napster-dies}.  Gnutella~\cite{gnutella-ripeanu} and Freenet~\cite{freenet-ian,freenet-theo} survived but had completely unstructured designs that compromised performance and search completeness.  Other peer-to-peer systems built on Napster's ideas or Gnutella's protocol and were eventually shut down~\cite{kazaa,kazaa-dies,morpheus-dies,grokster-dies} as Napster was.  The situation called both for better protocol design and for applications other than file sharing.

Chord~\cite{chord}, CAN~\cite{can}, Pastry~\cite{pastry}, Tapestry~\cite{tapestry}, and Kademlia~\cite{kademlia} collectively introduced the idea of structured, decentralized overlay networks.  The abstraction they implemented was a distributed hash table, or DHT, mapping fixed-size, opaque keys to arbitrary values.  All of the DHTs were efficient, requiring just $O(lg~n)$ or $O(n^{1/k})$ operations to route to a key in an $n$-node system.

Soon after, distributed file systems like the Cooperative File System (CFS)~\cite{cfs} and PAST~\cite{past-hotos} were built on top of DHTs.  At least initially, however, neither the DHTs nor the distributed file systems provided any search functionality.

In 2002, we set out to design a complete, efficient keyword search service~\cite{reynolds2003} for applications based on DHTs.

This paper revisits our original paper, surveys some of the research on peer-to-peer keyword searching that followed, examines the state of peer-to-peer technologies today, and identifies some of the lasting impacts that peer-to-peer networks have had.

\subsection{A definition}

In 2001 as well as today, the definition of a peer-to-peer system is a fuzzy one.  The most prominent distinguishing characteristic of a peer-to-peer system is that nodes owned by individuals make up the bulk of both the consumers (clients) and providers (servers) of the service.  A peer-to-peer service generally uses bandwidth, storage, and/or CPU time provided by users of the service.  Further, a robust peer-to-peer service should be decentralized enough that no administrator can disable the system.

Some prominent peer-to-peer services, including Napster, Skype prior to 2012, and all BitTorrent search pages, rely on centralized components that can or could be administratively disabled.  We still consider them peer-to-peer services, albeit ones with room for improvement.

\section{Efficient peer-to-peer searching}

A good peer-to-peer search feature needs to be decentralized, efficient, and complete.  Early peer-to-peer systems were not.  Napster's search feature was centralized, which made it unscalable and easy to shut down.  Gnutella's search feature was both inefficient and incomplete: it flooded queries throughout the network up to a fixed radius $TTL$, but it could not locate any resources more than $TTL$ hops away from the requestor.  Early DHTs did not provide search at all.

\subsection{Our contribution}

The simplest implementation of keyword search on a DHT is an {\em inverted index}, a shown in Figure~\ref{naive}.  The DHT maps each keyword to a list of all documents containing that keyword.  A client performing a search for one keyword retrieves the list of documents associated with that keyword.  To perform a conjunctive (``and'') query of multiple keywords, the client retrieves the list of documents for each keyword and locally calculates the intersection.  This approach is clearly decentralized and complete, but it is not especially efficient.  If the user searches for keywords that individually appear in many documents but that rarely appear together, then downloading the entire document list for each word is wasteful.

\begin{figure}[t]
\begin{center}
\mbox{\subfigure[\small A simple approach to ``AND''
queries.  Each node stores a list of document IDs corresponding to one
keyword.]{
\scalebox{0.53}{\input{post-scheme-naive}}
\label{naive}
}\quad\quad\quad
\subfigure[\small Bloom filters help reduce the bandwidth requirement of ``AND'' queries.  $F(A)$ is a Bloom filter representing the set $A$, and $B\cap F(A)$ is the set of all elements from $B$ that matched the Bloom filter $F(A)$.]{
\scalebox{0.53}{\input{post-scheme-bloom2}}
\label{bloom}
}}
\end{center}
\caption{Adding a Bloom filter to DHT search}
\end{figure}

\begin{figure}[t]
\begin{center}
\mbox{\subfigure[\small $F(A)$ is already in the cache at node $s_B$.]{
\scalebox{0.53}{\input{post-scheme-caching}}
\label{caching}
}\quad\quad\quad
\subfigure[\small Nodes send their data one chunk at a time until the desired intersection size is reached.]{
\scalebox{0.53}{\input{post-scheme-chunks}}
\label{chunks}
}}
\end{center}
\caption{Caching and incremental results}
\end{figure}

Our paper proposed three optimizations to this simple approach: Bloom filters, caching, and incremental results.  For these to work, we changed the protocol so that intersections are calculated within the DHT, as shown in Figure~\ref{bloom}.  That is, the client sends the entire query---e.g., ``efficient AND network AND protocols''---to the node hosting the first keyword.  That node sends the remaining words in the query, along with a list of documents containing the first keyword, to the node responsible for the second keyword.  This second node calculates the intersection between the second keyword's document set and the document set it received from the first node.  Forwarding continues in this fashion until all keywords have been considered (all document sets have been intersected), at which point the last node sends the final list---identifiers of the documents containing all the keywords---back to the client.

{\bf Bloom filters}~\cite{bloom,summary-cache,mullin-1990} are a compact but lossy way to represent membership in a set.  They answer the question ``Is element $x$ in the set,'' occasionally returning false positives---a value of ``true'' even when $x$ is not in the set.  In our search system, we used them as a compact way to represent the set of documents that contain a given keyword.  Instead of transferring entire lists of documents matching one or more keywords, the system transferred Bloom filters representing those document lists.

{\bf Caching} reduces both network traffic and latency by avoiding the transfer of information that has been used recently.  Our system cached Bloom-encoded lists of documents matching a given keyword.  Figure~\ref{caching} shows an example where node $s_B$ already has the Bloom filter $F(A)$; the client sends the query directly to node $s_B$, and eliminating one hop and the cost of transferring $F(A)$.  Each cache hit eliminates one hop and the associated transfer cost.  Caching allowed us to use larger Bloom filters, with a correspondingly lower false-positive rate.

{\bf Incremental results} take advantage of the fact that users often only want a few results---say, the best ten---even when many documents match their query.  At each hop, our system transferred only a few Bloom filter-encoded document IDs at a time, rather than the whole list.  This optimization tied the cost of answering a query to the size of the answer the user wanted, rather than to the total number of results available.  Figure~\ref{chunks} shows an example in which three chunks of the document list $A$ are sent, and then the requested result size is reached.

In addition, our system incorporated the idea of virtual hosts~\cite{cfs}.  Peer-to-peer systems are often heterogeneous in their capabilities: nodes differ in their available CPU power and network capacity.  Assigning more-capable nodes a larger number of virtual hosts let us take advantage of their additional capacity.

We measured the effectiveness of our optimizations using a corpus of 105,593 HTML documents and a trace of 95,409 web searches.  For each query, we calculated the number of bytes transferred and the total time for the system to satisfy the query.  Taken together, our optimizations reduced the time to answer a query by about an order of magnitude.

\subsection{PIER}

To be written~\cite{pier}.

\subsection{Planetp}

To be written~\cite{planetp}.

\subsection{OverCite}

To be written~\cite{overcite}.

\subsection{InfoBeacons}

To be written~\cite{infobeacons}.

\section{Where we are now}

Fifteen years have passed since Napster was released, and ten years have passed since the first peer-to-peer search papers were published.  Where are we now?

Very few prominent Internet services or businesses use peer-to-peer technology.  The most successful peer-to-peer system by far is file sharing, accounting for 10\% to 20\% of traffic during peak hours, on fixed (not mobile) networks~\cite{sandvine}.  The only other peer-to-peer system that is a household name in the U.S.---clearly a subjective distinction on our part---is Spotify.  Skype used to rely on a peer-to-peer overlay but no longer does.  Peer-to-peer networks are also popular for live and on-demand video streaming services in China.

Spotify's network is a hybrid of client-server and peer-to-peer protocols.  Each client keeps a persistent connection open to a Spotify server, through which it can browse available content, learn about other clients currently online, and receive the first fifteen seconds of any song where low latency is required.  Desktop (not mobile) clients retrieve full songs directly from other clients whenever possible.  Clients form an unstructured overlay network and use flooding queries with a TTL of two to search for songs.

Spotify's central servers make the peer-to-peer protocol simpler by providing lists of online clients and by providing a backstop data source for content not present within two overlay hops.  The peer-to-peer network offloads the majority of song download traffic~\cite{spotify}.

Skype originally used peer-to-peer technology to provide a user directory and NAT traversal~\cite{skype-p2p}.  Audio and video streams and chat messages go directly from one user to another whenever possible.  {\em Supernodes} maintain list of logged-in users and a current IP address for each one.  Supernodes also assist in routing calls and chat messages to clients whose device is suspended or behind a firewall.  In 2012, Skype disabled supernode functionality on end-user PCs and created dedicated {\em mega-supernodes} in data centers run by Microsoft~\cite{skype-no-p2p,skype-blog}.

Two large, live-video streaming services in China, PPS.tv (PPStream) and Funshion use peer-to-peer technology.  PPStream uses the DONet protocol, which is an unstructured, mesh-style multicast~\cite{ppstream,donet}.  Funshion is based on BitTorrent~\cite{funshion-bt}.

%%WRITEME: others that have abandoned p2p?  backup apps?  streaming apps?

\subsection{Disadvantages}

From the perspective of running an Internet service, peer-to-peer systems couple some desirable properties with some serious challenges.  The most appealing property of peer-to-peer systems is that it lets a business use customers' bandwidth and computing resources without paying for them.  But in most cases, the challenges overwhelm this potential cost savings:

\begin{itemize}
\item Most last-mile connections have asynchronous bandwidth, heavily favoring downloads over uploads.  A bandwidth-limited peer-to-peer service like file sharing or video streaming must therefore find many uploaders for each downloader.
\item End-user network connections, especially when geographically distributed from each other, have roughly 1000 times lower bandwidth and 1000 times higher latency than connections within a data center.
\item Using customers' computers in unexpected ways can lead to bad publicity.
\item Peer-to-peer services require users to download and install software, which providers must then write and maintain for each target platform.  An unmodified web browser can access centralized services, but not peer-to-peer services.
\item Customers turn off their computers more often than data centers do.
\item Mobile devices, which account for a rapidly increasing fraction of Internet traffic~\cite{sandvine}, magnify all of these issues: they are battery- and CPU-constrained, their bandwidth is usually slower and often metered, and they cannot run the same client software as desktop PCs.
\item Customer-owned nodes are not trustworthy.
\item Services with data retention or wiretap requirements will likely find it easier to comply with the law if infrastructure is centralized~\cite{skype-calea}.
\end{itemize}

Some of the limitations of customer-owned computing resources, particularly security and reliability, can be overcome with software, at a cost of additional redundancy and complexity.  Others, including their poor network connections and customers' aversion to installing additional software, are more stubborn.  Overall, the risks and costs of harnessing customer-owned resources are almost always higher than the risks and costs of running services in professionally managed data centers.

Further, hosted computing, storage, and bandwidth resources have gotten dramatically cheaper per unit in the last decade~\cite{hosting-costs}.  Utility computing, both infrastructure as a service (IaaS) and platform as a service (PaaS), allows new Internet services to start out cheaply with just a fraction of a single server, without relying on peer-to-peer systems.  Both Amazon and Google offer a resource-limited tier of hosting services for free.  At this point, even cash-strapped startups favor starting new Internet services in data centers.

Web search in particular is a service that favors data centers over peer-to-peer systems.  Our test corpus contained 105,593 documents, while Google's contains around fifty billion.  A fully featured web search service does things like spelling suggestions, autocomplete, instant search, location awareness, and personalization that are not amenable to caching or representation in Bloom filters.  Our search protocol masks wide-area bandwidth and latency constraints well enough for the demands of a file-sharing service, perhaps, but not well enough to be competitive with a modern search engine built with dedicated computing resources.

\subsection{Advantages}

In spite of the challenges, the most popular file-sharing services still use peer-to-peer systems~\cite{sandvine,bittorrent,edonkey,ares}.  We believe that this fact is due almost entirely to censorship resistance.  No matter how widely replicated an infrastructure-based service is, it is still vulnerable to a well placed letter, phone call, domain seizure, or DMCA takedown notice.  Peer-to-peer systems have proven far more resilient.  In 1993, John Gilmore said, ``The Net interprets censorship as damage and routes around it''~\cite{gilmore-time}.  Peer-to-peer systems codify that ideal in software.

Much of the censorship exercised against web sites and peer-to-peer systems is copyright related.  Publishers of movies, songs, books, and software, among others, hope to preserve their ability to charge for each copy made of their copyrighted works.  However, censorship happens for other reasons, too.  For example:

\begin{itemize}
\item {\bf Political} - In 2008, both the McCain~\cite{mccain-dmca} and Obama~\cite{obama-dmca} campaigns had political messages removed due to DMCA takedown notices.  Also in 2008, during the South Ossetia War, the nation of Georgia blocked all websites with addresses ending in {\tt .ru}~\cite{georgia-russia}.
\item {\bf Moral} - Russia has instituted a secret blacklist of sites relating to drugs, suicide, or pornography~\cite{russia-bbc}.  The United Kingdom is creating its own list, currently optional but enabled by default, to restrict access to pornography; web forums; information about violence, terrorism, and eating disorders; and ``esoteric material''~\cite{uk-blacklist}.
\item {\bf Security} - Volkswagen successfully sued to censor research about vulnerabilities in its keyless entry systems~\cite{vw-jalopnik}.  Life science researchers have instituted policies for censoring themselves when research seems to pose more risk than social good~\cite{who-bulletin}.\item {\bf Competitive} - Universal Music Group briefly had Megaupload's ``Mega Song'' removed from YouTube, despite not having any copyright claim against it~\cite{mega-song}.
\item {\bf Suppressing criticism} - KTVU used DMCA takedown requests to remove copies of a newscast in which its anchor read obviously fake and offensive names for the pilots of Asiana flight 214~\cite{asiana}.
\item {\bf Accidental} - The U.S. Immigration and Customs Enforcement (ICE) accidentally took down the hip-hop music blog \url{dajaz1.com} for a year before returning it without explanation~\cite{dajaz1}.  YouTube's Content ID system automatically flags videos for possible removal, but doesn't always get it right; Content ID also cannot assess the potential that a video might fall under fair use~\cite{content-id}.  While attempting to prevent unauthorized distribution of Windows~8 and Office, Microsoft has accidentally sent takedown notices for the BBC, Wikipedia, and OpenOffice, among others~\cite{microsoft-win8,microsoft-office}.
\end{itemize}
In each case, censorship was possible because a small number of administrative entities---ISPs, domain registrars, YouTube, research conference organizers, etc.---could be compelled to block or remove the content.  Peer-to-peer systems provide an alternative distribution channel for content when censors get too heavy handed.

Formal peer-to-peer systems are not the only way that the Internet routes around censorship.  Content that is small and not obviously offensive or copyright-infringing will often end up widely distributed and widely mirrored if someone tries to censor it.  Far more people know what Barbara Streisand's house looks like, how badly the Suburban Express bus company treats its customers, and how to 3D print a gun than would have if the interested parties hadn't attempted to censor that information~\cite{streisand,suburban-express,3d-guns-bbc}.  In a sense, technology news sites, parodies, memes, and web forums act like an informal peer-to-peer network when they mirror content in this fashion.

\subsection{Impacts}

Several aspects of peer-to-peer systems have found their way into centrally managed systems.  Most large-scale Internet services are geographically distributed, self-organizing, and resilient.  Some systems, including the Cassandra database and the Tahoe-LAFS file system, explicitly incorporate a DHT~\cite{cassandra,tahoe-lafs}.

Another platform that borrows ideas from peer-to-peer systems is BOINC, which runs SETI@home~\cite{boinc}.  Although it harvests CPU cycles from end users' computers, we do not consider BOINC to be a classic peer-to-peer system.  Worker nodes are essentially only servers---they do not consume the service that other nodes provide---and are centrally managed rather than self-organizing.  However, like a peer-to-peer system, BOINC successfully deals with malicious participants and harnesses spare CPU cycles.

\section{Where we go from here}

We believe that peer-to-peer systems continue to have both technical and social value.  They may be a good way for modestly funded research groups to bootstrap an Internet service.  They provide a stress test for new protocols; protocols and techniques that work within the resource and security constraints of a peer-to-peer system will often work even better in a centralized system.  And, of course, they provide outstanding resistance to censorship, in a way that commercial and centrally managed services cannot.

To that end, we believe the most important focus areas in peer-to-peer research are:
\begin{itemize}
\item {\bf Security} - Services that become popular, or that host content that someone wishes to censor, become the target of attacks.  Attackers may disrupt routing or searching, or they may intercept or modify content.  Peer-to-peer systems have to deal with the possibility that nodes are Byzantine faulty.
\item {\bf Anonymity} - If the main use case for peer-to-peer systems is distributing censored content, then participants might need to remain anonymous when publishing or retrieving that content.  Providing anonymity in a robust, efficient way could provide immense social value.
\item {\bf Searchability} - Simply put, we cannot read what we cannot find.  Right now, BitTorrent users rely on centralized, commercial web sites to map keywords to document identifiers.  Eventually, whether through legal changes or technical attacks, these sites will probably get shut down.  Existing and new peer-to-peer search technologies should be applied to ensure that users can find content.
\end{itemize}

In 2013, as in 2001, peer-to-peer networking remains an exciting, fruitful area of research.

\bibliography{search}
\bibliographystyle{plain}
\small

\end{document}